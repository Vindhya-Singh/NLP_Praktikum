{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Classification-Net",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "UQ1lLYsyvIzg",
        "0OlV5dgdfHKz"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VindhyaSRajan/NLP_Praktikum/blob/master/Accuracy_test_Classification_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daymP20xX_7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pandas import Series\n",
        "from google.colab import drive\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from tensorflow import summary\n",
        "from torch.utils.data import BatchSampler\n",
        "from collections import Counter\n",
        "from sklearn.metrics import f1_score,accuracy_score, confusion_matrix, classification_report\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-J64A0YqMvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionary for label to index, this has been pre-generated\n",
        "encoding_to_labels = {\n",
        "   2: \"Automotive\",                \n",
        "3: \"Baby\",                                          \n",
        "13:\"Digital_Ebook_Purchase\",    \n",
        "8: \"Digital_Music_Purchase\",    \n",
        "0: \"Digital_Video_Download\",    \n",
        "9: \"Electronics\",               \n",
        "12:\"Home\",                      \n",
        "1: \"Mobile_Apps\",                                   \n",
        "15:\"Musical Instruments\",                             \n",
        "7: \"Shoes\",                     \n",
        "19:\"Sports\",                    \n",
        "21:\"Toys\",                      \n",
        "14:\"Video\",                     \n",
        "5: \"Video DVD\",                  \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-JUCiTYsRWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_lebel_from_code(code):\n",
        "  if code not in encoding_to_labels.keys():\n",
        "    raise KeyError(\"Invalid Code\")\n",
        "  return encoding_to_labels[code]\n",
        "\n",
        "def get_all_labels():\n",
        "  return list(encoding_to_labels.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GNIm96jp_zhM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "856e3600-48eb-451f-f905-9649f8b42bdd"
      },
      "source": [
        "!pip install -q tb-nightly"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.9MB 2.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0QcrlYeTdBR-",
        "colab": {}
      },
      "source": [
        "# # Delete any old logs.... be smart while using this\n",
        "% rm -rf /content/logs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rOreic85dBSC",
        "colab": {}
      },
      "source": [
        "% mkdir -p '/content/logs/tensorboard/train/'\n",
        "% mkdir -p '/content/logs/tensorboard/val/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfajFKSRoqSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eENbB1ut3MPP",
        "colab_type": "text"
      },
      "source": [
        "#Read the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERTjB0zztxnN",
        "colab_type": "code",
        "outputId": "d517d8fe-d724-49da-da97-4e708c051fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Vo2FWUWwnbv",
        "outputId": "c56791ef-ee81-4344-b8e4-2ae722b4b463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/\n",
        "test_data = pd.read_pickle('/content/drive/My Drive/dtest_20k_accuracytest_encoded_labelsmappedandreduced.pkl')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lptdySB3giiT",
        "colab_type": "code",
        "outputId": "0c231908-1c24-4ad4-be18-770605225f1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_embedding</th>\n",
              "      <th>labels_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[0.020630155, -5.427392e-05, -0.0005429585, 0...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[0.009404534, -0.00013506821, 0.0029931439, 0...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[0.0118809715, -1.7096989e-05, 0.017329859, 0...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[0.013619319, -0.000120394856, -0.00017446173...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[0.013776152, 0.0014088053, 0.0023799718, 0.0...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  sentence_embedding  labels_encoded\n",
              "0  [[0.020630155, -5.427392e-05, -0.0005429585, 0...               2\n",
              "1  [[0.009404534, -0.00013506821, 0.0029931439, 0...               2\n",
              "2  [[0.0118809715, -1.7096989e-05, 0.017329859, 0...               2\n",
              "3  [[0.013619319, -0.000120394856, -0.00017446173...               2\n",
              "4  [[0.013776152, 0.0014088053, 0.0023799718, 0.0...               2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5XVwbe1mwnb2",
        "outputId": "01646222-02c5-4471-e22b-5ddf7dda5edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_data)\n",
        "# test_data.columns"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13184"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLsdLnjKiAr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_selection(data_frame, num_samples):\n",
        "  sampled_df = data_frame.sample(n=num_samples)\n",
        "  return sampled_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuGOnw02iwOb",
        "colab_type": "code",
        "outputId": "6c3d6ff6-7026-4b2d-bbb2-1ab14e6da391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_list = set(test_data.labels_encoded)\n",
        "class_list"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 5, 7, 8, 9, 13, 14, 15, 19, 21, 22}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaHi2dZ9hInA",
        "colab_type": "code",
        "outputId": "a5d7ce49-a92a-4cf9-f24d-f38502c1574d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_per_class_dict = dict()\n",
        "for label_type in class_list:\n",
        "    df_per_class_dict[label_type] = test_data[test_data.labels_encoded == label_type]\n",
        "    \n",
        "df_per_class_dict.keys() "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([0, 1, 2, 3, 5, 7, 8, 9, 13, 14, 15, 19, 21, 22])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwbsYlEZoyuV",
        "colab_type": "code",
        "outputId": "6077ad16-2eaf-424b-f7f8-132c365647c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "for key, val in df_per_class_dict.items():\n",
        "  print(\"Key has {} and length of list is {}\".format(key, len(val)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Key has 0 and length of list is 999\n",
            "Key has 1 and length of list is 999\n",
            "Key has 2 and length of list is 402\n",
            "Key has 3 and length of list is 794\n",
            "Key has 5 and length of list is 999\n",
            "Key has 7 and length of list is 999\n",
            "Key has 8 and length of list is 999\n",
            "Key has 9 and length of list is 999\n",
            "Key has 13 and length of list is 999\n",
            "Key has 14 and length of list is 999\n",
            "Key has 15 and length of list is 999\n",
            "Key has 19 and length of list is 999\n",
            "Key has 21 and length of list is 999\n",
            "Key has 22 and length of list is 999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cyvqVc_n2K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_samples_per_class = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ctQNJu9kBh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://pandas.pydata.org/pandas-docs/version/0.18/merging.html\n",
        "def create_random_frame(df_per_class, num_samples):\n",
        "    list_of_seed_df = []\n",
        "    list_of_test_df = []\n",
        "    for cat,data_frame_of_class in df_per_class.items():\n",
        "        random_df = random_selection(data_frame_of_class, num_samples)\n",
        "        # https://stackoverflow.com/questions/42363706/how-to-extract-rows-in-a-pandas-dataframe-not-in-a-subset-dataframe\n",
        "        extract_idx = list(set(data_frame_of_class.index) - set(random_df.index))\n",
        "        remaining_terms = data_frame_of_class.loc[extract_idx]\n",
        "        list_of_seed_df.append(random_df)\n",
        "        list_of_test_df.append(remaining_terms)\n",
        "    train_set_df = pd.concat(list_of_seed_df)\n",
        "    test_set_df = pd.concat(list_of_test_df)\n",
        "    return train_set_df, test_set_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE3ECzPNoECf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, test_df = create_random_frame(df_per_class_dict, num_samples_per_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx7WPaTzn8mo",
        "colab_type": "code",
        "outputId": "fa34575b-82b4-4b6e-e7dc-330453294083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "train_df.groupby(train_df.labels_encoded).count()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_embedding</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels_encoded</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                sentence_embedding\n",
              "labels_encoded                    \n",
              "0                                1\n",
              "1                                1\n",
              "2                                1\n",
              "3                                1\n",
              "5                                1\n",
              "7                                1\n",
              "8                                1\n",
              "9                                1\n",
              "13                               1\n",
              "14                               1\n",
              "15                               1\n",
              "19                               1\n",
              "21                               1\n",
              "22                               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev0UhPKLrq__",
        "colab_type": "code",
        "outputId": "1207b370-c899-4f32-fbf6-fb68d0557f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "test_df.groupby(test_df.labels_encoded).count()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_embedding</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels_encoded</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                sentence_embedding\n",
              "labels_encoded                    \n",
              "0                              998\n",
              "1                              998\n",
              "2                              401\n",
              "3                              793\n",
              "5                              998\n",
              "7                              998\n",
              "8                              998\n",
              "9                              998\n",
              "13                             998\n",
              "14                             998\n",
              "15                             998\n",
              "19                             998\n",
              "21                             998\n",
              "22                             998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE9hfpyts0Pr",
        "colab_type": "code",
        "outputId": "1a1dfc2b-b02d-4d6b-ce7b-365668efd5bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(train_df.sentence_embedding.isin(test_df.sentence_embedding)).sum() == 0"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHPAPG1ogqiO",
        "colab_type": "text"
      },
      "source": [
        "# The three networks that need to be loaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbJFhGMaM-A3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TripletNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(TripletNetwork, self).__init__()\n",
        "\n",
        "        self.input_dim=1024\n",
        "        self.fc = nn.Sequential(nn.Linear(1024, 512),\n",
        "                                  nn.BatchNorm1d(num_features=512),\n",
        "                                  nn.ReLU(),\n",
        "                                  #nn.Dropout(),\n",
        "                                  nn.Linear(512,256),\n",
        "                                  nn.BatchNorm1d(num_features=256),\n",
        "                                  nn.ReLU(),\n",
        "                                  #nn.Dropout(p=0.6),\n",
        "                                  nn.Linear(256,64) #earlier 64\n",
        "                               )\n",
        "       \n",
        "    def forward(self, x1, x2, x3):\n",
        "       \n",
        "        \"\"\"\n",
        "          We updated the network now and are directly getting the sentence embeddings\n",
        "        \"\"\"\n",
        "        # These are the embeddings and what we want to achieve is to make\n",
        "        # these embeddings which should be in the same region denoting their language to\n",
        "        # fall a bit away based on the task at hand\n",
        "        output1 = self.fc(x1.cuda())\n",
        "        output2 = self.fc(x2.cuda())\n",
        "        output3 = self.fc(x3.cuda())\n",
        "        \n",
        "        return (output1, output2, output3)\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        return self.encoder.encode_sentences(sentences = x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVI_Mn79OkcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClassificationNet(nn.Module):\n",
        "  \n",
        "\n",
        "  def __init__(self, embedding_network, num_classes):\n",
        "    super(ClassificationNet, self).__init__()\n",
        "    self.embedding_network = embedding_network #We would like to freeze these embeddings\n",
        "    self.num_classes = num_classes\n",
        "    self.nonlinear = nn.ReLU()\n",
        "    self.fc1 = nn.Linear(64, 64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, self.num_classes)\n",
        "    # Freeze the weights of this network\n",
        "    \"\"\" This attempt is to first allow classification network to train\"\"\"\n",
        "    for param in self.embedding_network.fc.parameters():\n",
        "           param.requires_grad = False\n",
        "    \n",
        "  \n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.embedding_network.fc(x)\n",
        "    x = self.fc1(self.nonlinear(x))\n",
        "    x = self.fc2(self.nonlinear(x))\n",
        "    x = self.fc3(self.nonlinear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX8B_3GoT9c7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to define a specific dataloader in this case, which shall be frankly, quite simple and dummy\n",
        "class SoftmaxDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Train: For each sample (anchor) randomly chooses a positive and negative samples\n",
        "    Test: Creates fixed triplets for testing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, select_column):\n",
        "         \n",
        "        \n",
        "        self.dataset = dataset\n",
        "        self.train_labels = self.dataset.labels_encoded\n",
        "            # Drop the labels column so that remaining features form part of the training set\n",
        "        self.dataset = self.dataset.drop('labels_encoded', axis=1)\n",
        "        self.train_data = self.dataset\n",
        "        self.select_column = select_column\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        #print(type(self.train_data))\n",
        "        selected_frame, label = self.train_data.iloc[index], self.train_labels.iloc[index]\n",
        "        str_data = selected_frame[self.select_column]\n",
        "\n",
        "        return str_data, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ1lLYsyvIzg",
        "colab_type": "text"
      },
      "source": [
        "# Classification Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC0nL-sYSOcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global declarations\n",
        "num_classes=23\n",
        "num_epochs = 200\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MjSwcL7J0zZm",
        "outputId": "5b954561-5f43-4737-f0c8-f689bdb782da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# Load a pre-existing model \n",
        "PATH = '/content/11-model-GOOD.pth'\n",
        "model = TripletNetwork()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TripletNetwork(\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=256, out_features=64, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzXYFUDYRZtZ",
        "colab_type": "code",
        "outputId": "ce43f243-91af-4951-db0d-65caf8be2c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "num_classes = max(set(train_df.labels_encoded)) + 1\n",
        "net = ClassificationNet(embedding_network=model, num_classes=num_classes)\n",
        "net.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassificationNet(\n",
              "  (embedding_network): TripletNetwork(\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "      (6): Linear(in_features=256, out_features=64, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (nonlinear): ReLU()\n",
              "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=23, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4kYkHpsRaoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptV1nJq2YM4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "softmax_train_dataset = SoftmaxDataset(dataset=train_df,select_column='sentence_embedding')\n",
        "softmax_test_dataset = SoftmaxDataset(dataset=test_df,select_column='sentence_embedding')\n",
        "# Now the dataloaders need to be defined as well\n",
        "classification_train_loader = DataLoader(softmax_train_dataset, batch_size=batch_size,shuffle=True)\n",
        "classification_test_loader = DataLoader(softmax_test_dataset, batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WfPWuYg3GkKg",
        "colab": {}
      },
      "source": [
        "train_writer = SummaryWriter('/content/logs/tensorboard/train/')\n",
        "val_writer = SummaryWriter('/content/logs/tensorboard/val/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXkjJP4dQ0m1",
        "colab_type": "code",
        "outputId": "70e7721a-74e6-406b-ce2a-e5708456f296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Next we need to train this network in order to learn the weights of the fc layer and cross entropy weights\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(classification_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "        #reshape the input to align\n",
        "        batch_size = inputs.shape[0]\n",
        "        inputs = inputs.reshape(batch_size,-1)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Write the scalars\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).cpu().sum().item()\n",
        "    print(\"loss is {}\".format(running_loss/total))   \n",
        "    print('Accuracy of the network on the train samples: {} '.format((100 * correct / total)))\n",
        "    train_writer.add_scalar('Loss', running_loss/total,epoch)\n",
        "    train_writer.add_scalar('Accuracy', 100*correct/total,epoch)\n",
        "    # Now this is the section for testing the model in the same epoch\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_val = 0\n",
        "    with torch.no_grad():\n",
        "        for data in classification_test_loader:\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.cuda()\n",
        "            batch_size = inputs.shape[0]\n",
        "            inputs = inputs.reshape(batch_size,-1)\n",
        "            # Next the evaluation\n",
        "            outputs = net(inputs)\n",
        "            labels = labels.cuda()\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss_val = loss_val + loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).cpu().sum().item()\n",
        "            \n",
        "    print('Accuracy of the network on the test samples:{}'.format(\n",
        "        (100 * correct / total)))\n",
        "    print(\"epoch is {} loss validation set is {}\".format(epoch, loss_val/total)) \n",
        "    torch.save(net.state_dict(), '/content/{}-classifier.pth'.format(epoch))\n",
        "    val_writer.add_scalar('Loss', loss_val/total,epoch)\n",
        "    val_writer.add_scalar('Accuracy', 100*correct/total,epoch)\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss is 0.04459913969039917\n",
            "Accuracy of the network on the train samples: 7.857142857142857 \n",
            "Accuracy of the network on the test samples:5.136461208218338\n",
            "epoch is 0 loss validation set is 0.03140084645163973\n",
            "loss is 0.04440448795046125\n",
            "Accuracy of the network on the train samples: 5.0 \n",
            "Accuracy of the network on the test samples:5.749770009199632\n",
            "epoch is 1 loss validation set is 0.031244066148329204\n",
            "loss is 0.04383443934576852\n",
            "Accuracy of the network on the train samples: 11.428571428571429 \n",
            "Accuracy of the network on the test samples:7.727690892364305\n",
            "epoch is 2 loss validation set is 0.031082401810084263\n",
            "loss is 0.0435438905443464\n",
            "Accuracy of the network on the train samples: 12.142857142857142 \n",
            "Accuracy of the network on the test samples:9.306961054891138\n",
            "epoch is 3 loss validation set is 0.030912430529139664\n",
            "loss is 0.04333219528198242\n",
            "Accuracy of the network on the train samples: 14.285714285714286 \n",
            "Accuracy of the network on the test samples:9.858938975774302\n",
            "epoch is 4 loss validation set is 0.03072531188203308\n",
            "loss is 0.042953259604317805\n",
            "Accuracy of the network on the train samples: 12.857142857142858 \n",
            "Accuracy of the network on the test samples:10.081263416130021\n",
            "epoch is 5 loss validation set is 0.03053906760088544\n",
            "loss is 0.04269410371780395\n",
            "Accuracy of the network on the train samples: 12.857142857142858 \n",
            "Accuracy of the network on the test samples:10.571910456915056\n",
            "epoch is 6 loss validation set is 0.03032085071930451\n",
            "loss is 0.04201584543500628\n",
            "Accuracy of the network on the train samples: 12.142857142857142 \n",
            "Accuracy of the network on the test samples:10.870898497393437\n",
            "epoch is 7 loss validation set is 0.030088260673884416\n",
            "loss is 0.041450796808515274\n",
            "Accuracy of the network on the train samples: 11.428571428571429 \n",
            "Accuracy of the network on the test samples:11.277215578043545\n",
            "epoch is 8 loss validation set is 0.02984285137105741\n",
            "loss is 0.04141851663589478\n",
            "Accuracy of the network on the train samples: 13.571428571428571 \n",
            "Accuracy of the network on the test samples:11.553204538485128\n",
            "epoch is 9 loss validation set is 0.029564416708298454\n",
            "loss is 0.04066704511642456\n",
            "Accuracy of the network on the train samples: 14.285714285714286 \n",
            "Accuracy of the network on the test samples:12.020852499233364\n",
            "epoch is 10 loss validation set is 0.029285519922192717\n",
            "loss is 0.039982935360499794\n",
            "Accuracy of the network on the train samples: 17.857142857142858 \n",
            "Accuracy of the network on the test samples:12.77215578043545\n",
            "epoch is 11 loss validation set is 0.028982815659144876\n",
            "loss is 0.03969969749450684\n",
            "Accuracy of the network on the train samples: 16.428571428571427 \n",
            "Accuracy of the network on the test samples:13.791781662066851\n",
            "epoch is 12 loss validation set is 0.028675630720653843\n",
            "loss is 0.039075735637119836\n",
            "Accuracy of the network on the train samples: 19.285714285714285 \n",
            "Accuracy of the network on the test samples:14.251763262802822\n",
            "epoch is 13 loss validation set is 0.02837262059310871\n",
            "loss is 0.037979170254298616\n",
            "Accuracy of the network on the train samples: 21.428571428571427 \n",
            "Accuracy of the network on the test samples:14.918736583869979\n",
            "epoch is 14 loss validation set is 0.0280412697090177\n",
            "loss is 0.03772222314562116\n",
            "Accuracy of the network on the train samples: 22.142857142857142 \n",
            "Accuracy of the network on the test samples:15.225390984360626\n",
            "epoch is 15 loss validation set is 0.02772768331210111\n",
            "loss is 0.036577318395887105\n",
            "Accuracy of the network on the train samples: 25.714285714285715 \n",
            "Accuracy of the network on the test samples:15.823367065317388\n",
            "epoch is 16 loss validation set is 0.02743333740784178\n",
            "loss is 0.03679408516202654\n",
            "Accuracy of the network on the train samples: 27.142857142857142 \n",
            "Accuracy of the network on the test samples:16.068690585709906\n",
            "epoch is 17 loss validation set is 0.027156963227022574\n",
            "loss is 0.03593757152557373\n",
            "Accuracy of the network on the train samples: 27.857142857142858 \n",
            "Accuracy of the network on the test samples:15.999693345599509\n",
            "epoch is 18 loss validation set is 0.026892685480769958\n",
            "loss is 0.035229556901114324\n",
            "Accuracy of the network on the train samples: 25.714285714285715 \n",
            "Accuracy of the network on the test samples:15.792701625268323\n",
            "epoch is 19 loss validation set is 0.026633382812302306\n",
            "loss is 0.03487665823527745\n",
            "Accuracy of the network on the train samples: 29.285714285714285 \n",
            "Accuracy of the network on the test samples:15.37871818460595\n",
            "epoch is 20 loss validation set is 0.026410620386561744\n",
            "loss is 0.03471752064568656\n",
            "Accuracy of the network on the train samples: 28.571428571428573 \n",
            "Accuracy of the network on the test samples:15.532045384851273\n",
            "epoch is 21 loss validation set is 0.026151704938087827\n",
            "loss is 0.03357728379113334\n",
            "Accuracy of the network on the train samples: 30.714285714285715 \n",
            "Accuracy of the network on the test samples:15.125728304201166\n",
            "epoch is 22 loss validation set is 0.02595249985449521\n",
            "loss is 0.03247504234313965\n",
            "Accuracy of the network on the train samples: 35.0 \n",
            "Accuracy of the network on the test samples:15.470714504753143\n",
            "epoch is 23 loss validation set is 0.025772862440236174\n",
            "loss is 0.03334243638174875\n",
            "Accuracy of the network on the train samples: 32.142857142857146 \n",
            "Accuracy of the network on the test samples:15.700705305121128\n",
            "epoch is 24 loss validation set is 0.02556569734916699\n",
            "loss is 0.03256852286202567\n",
            "Accuracy of the network on the train samples: 35.714285714285715 \n",
            "Accuracy of the network on the test samples:15.501379944802208\n",
            "epoch is 25 loss validation set is 0.025398759197070166\n",
            "loss is 0.032138468538011826\n",
            "Accuracy of the network on the train samples: 36.42857142857143 \n",
            "Accuracy of the network on the test samples:16.367678626188287\n",
            "epoch is 26 loss validation set is 0.025255276340898726\n",
            "loss is 0.031319149902888706\n",
            "Accuracy of the network on the train samples: 35.0 \n",
            "Accuracy of the network on the test samples:17.049984667279976\n",
            "epoch is 27 loss validation set is 0.02509800993347051\n",
            "loss is 0.03148900440761021\n",
            "Accuracy of the network on the train samples: 40.0 \n",
            "Accuracy of the network on the test samples:16.90432382704692\n",
            "epoch is 28 loss validation set is 0.025057194021646686\n",
            "loss is 0.03059248583657401\n",
            "Accuracy of the network on the train samples: 37.857142857142854 \n",
            "Accuracy of the network on the test samples:16.651333946642133\n",
            "epoch is 29 loss validation set is 0.024955601989765982\n",
            "loss is 0.03095736333302089\n",
            "Accuracy of the network on the train samples: 41.42857142857143 \n",
            "Accuracy of the network on the test samples:16.74333026678933\n",
            "epoch is 30 loss validation set is 0.024942700115678795\n",
            "loss is 0.03048090934753418\n",
            "Accuracy of the network on the train samples: 42.142857142857146 \n",
            "Accuracy of the network on the test samples:16.344679546151486\n",
            "epoch is 31 loss validation set is 0.0249774579035289\n",
            "loss is 0.029491523333958217\n",
            "Accuracy of the network on the train samples: 38.57142857142857 \n",
            "Accuracy of the network on the test samples:16.130021465808035\n",
            "epoch is 32 loss validation set is 0.02494681835613233\n",
            "loss is 0.029100372110094343\n",
            "Accuracy of the network on the train samples: 40.0 \n",
            "Accuracy of the network on the test samples:16.314014106102423\n",
            "epoch is 33 loss validation set is 0.02489095829411249\n",
            "loss is 0.029307167870657784\n",
            "Accuracy of the network on the train samples: 39.285714285714285 \n",
            "Accuracy of the network on the test samples:16.084023305734437\n",
            "epoch is 34 loss validation set is 0.024921335040042458\n",
            "loss is 0.02894079259463719\n",
            "Accuracy of the network on the train samples: 37.857142857142854 \n",
            "Accuracy of the network on the test samples:16.1836859858939\n",
            "epoch is 35 loss validation set is 0.024875782724905145\n",
            "loss is 0.027931227854319982\n",
            "Accuracy of the network on the train samples: 47.857142857142854 \n",
            "Accuracy of the network on the test samples:16.85832566697332\n",
            "epoch is 36 loss validation set is 0.02482646787799015\n",
            "loss is 0.028460471970694404\n",
            "Accuracy of the network on the train samples: 42.142857142857146 \n",
            "Accuracy of the network on the test samples:17.272309107635696\n",
            "epoch is 37 loss validation set is 0.024841383990609766\n",
            "loss is 0.028318234852382114\n",
            "Accuracy of the network on the train samples: 43.57142857142857 \n",
            "Accuracy of the network on the test samples:17.333639987733825\n",
            "epoch is 38 loss validation set is 0.024794680726414844\n",
            "loss is 0.0282174961907523\n",
            "Accuracy of the network on the train samples: 40.0 \n",
            "Accuracy of the network on the test samples:17.44096902790555\n",
            "epoch is 39 loss validation set is 0.024863528825139314\n",
            "loss is 0.02785347104072571\n",
            "Accuracy of the network on the train samples: 45.714285714285715 \n",
            "Accuracy of the network on the test samples:17.594296228150874\n",
            "epoch is 40 loss validation set is 0.024888871089697836\n",
            "loss is 0.026789072581699918\n",
            "Accuracy of the network on the train samples: 45.714285714285715 \n",
            "Accuracy of the network on the test samples:17.16498006746397\n",
            "epoch is 41 loss validation set is 0.02496963289755687\n",
            "loss is 0.02700992056301662\n",
            "Accuracy of the network on the train samples: 44.285714285714285 \n",
            "Accuracy of the network on the test samples:17.1803127874885\n",
            "epoch is 42 loss validation set is 0.02500275699538857\n",
            "loss is 0.025990909337997435\n",
            "Accuracy of the network on the train samples: 45.0 \n",
            "Accuracy of the network on the test samples:16.704998466727996\n",
            "epoch is 43 loss validation set is 0.025131928485728816\n",
            "loss is 0.02675026399748666\n",
            "Accuracy of the network on the train samples: 45.0 \n",
            "Accuracy of the network on the test samples:16.88132474701012\n",
            "epoch is 44 loss validation set is 0.02517929368865742\n",
            "loss is 0.026551470586231776\n",
            "Accuracy of the network on the train samples: 42.857142857142854 \n",
            "Accuracy of the network on the test samples:16.973321067157315\n",
            "epoch is 45 loss validation set is 0.025298323360040707\n",
            "loss is 0.02708465542112078\n",
            "Accuracy of the network on the train samples: 41.42857142857143 \n",
            "Accuracy of the network on the test samples:17.41796994786875\n",
            "epoch is 46 loss validation set is 0.025210135738310803\n",
            "loss is 0.027013553040368215\n",
            "Accuracy of the network on the train samples: 43.57142857142857 \n",
            "Accuracy of the network on the test samples:17.356639067770622\n",
            "epoch is 47 loss validation set is 0.025197150223973848\n",
            "loss is 0.02584250399044582\n",
            "Accuracy of the network on the train samples: 42.142857142857146 \n",
            "Accuracy of the network on the test samples:17.509966268015948\n",
            "epoch is 48 loss validation set is 0.025205119224239514\n",
            "loss is 0.02532813038144793\n",
            "Accuracy of the network on the train samples: 44.285714285714285 \n",
            "Accuracy of the network on the test samples:18.215271389144434\n",
            "epoch is 49 loss validation set is 0.02512307883186305\n",
            "loss is 0.025472245046070645\n",
            "Accuracy of the network on the train samples: 48.57142857142857 \n",
            "Accuracy of the network on the test samples:18.14627414903404\n",
            "epoch is 50 loss validation set is 0.025179001879962592\n",
            "loss is 0.024886591945375715\n",
            "Accuracy of the network on the train samples: 47.857142857142854 \n",
            "Accuracy of the network on the test samples:17.969947868751916\n",
            "epoch is 51 loss validation set is 0.025264026105349065\n",
            "loss is 0.02577027678489685\n",
            "Accuracy of the network on the train samples: 47.857142857142854 \n",
            "Accuracy of the network on the test samples:18.10027598896044\n",
            "epoch is 52 loss validation set is 0.025282768631449362\n",
            "loss is 0.02451122488294329\n",
            "Accuracy of the network on the train samples: 48.57142857142857 \n",
            "Accuracy of the network on the test samples:18.092609628948175\n",
            "epoch is 53 loss validation set is 0.025396486653465684\n",
            "loss is 0.023939686162131175\n",
            "Accuracy of the network on the train samples: 49.285714285714285 \n",
            "Accuracy of the network on the test samples:18.130941429009507\n",
            "epoch is 54 loss validation set is 0.025420017803201498\n",
            "loss is 0.025649149077279228\n",
            "Accuracy of the network on the train samples: 51.42857142857143 \n",
            "Accuracy of the network on the test samples:18.268935909230297\n",
            "epoch is 55 loss validation set is 0.025583825422846734\n",
            "loss is 0.02401557905333383\n",
            "Accuracy of the network on the train samples: 51.42857142857143 \n",
            "Accuracy of the network on the test samples:18.215271389144434\n",
            "epoch is 56 loss validation set is 0.025598773631681077\n",
            "loss is 0.02301714335169111\n",
            "Accuracy of the network on the train samples: 52.857142857142854 \n",
            "Accuracy of the network on the test samples:17.931616068690587\n",
            "epoch is 57 loss validation set is 0.025627340341191903\n",
            "loss is 0.023247555324009486\n",
            "Accuracy of the network on the train samples: 52.857142857142854 \n",
            "Accuracy of the network on the test samples:18.14627414903404\n",
            "epoch is 58 loss validation set is 0.0257707386797683\n",
            "loss is 0.023169387238366264\n",
            "Accuracy of the network on the train samples: 54.285714285714285 \n",
            "Accuracy of the network on the test samples:18.291934989267094\n",
            "epoch is 59 loss validation set is 0.02585589275225581\n",
            "loss is 0.022157331023897442\n",
            "Accuracy of the network on the train samples: 56.42857142857143 \n",
            "Accuracy of the network on the test samples:18.14627414903404\n",
            "epoch is 60 loss validation set is 0.025898760409122666\n",
            "loss is 0.024056075300489154\n",
            "Accuracy of the network on the train samples: 45.714285714285715 \n",
            "Accuracy of the network on the test samples:18.08494326893591\n",
            "epoch is 61 loss validation set is 0.025934014865789848\n",
            "loss is 0.0214053784097944\n",
            "Accuracy of the network on the train samples: 55.714285714285715 \n",
            "Accuracy of the network on the test samples:17.916283348666052\n",
            "epoch is 62 loss validation set is 0.025989682332243302\n",
            "loss is 0.022857754571097236\n",
            "Accuracy of the network on the train samples: 52.857142857142854 \n",
            "Accuracy of the network on the test samples:18.475927629561482\n",
            "epoch is 63 loss validation set is 0.025989123170853248\n",
            "loss is 0.02167984332357134\n",
            "Accuracy of the network on the train samples: 51.42857142857143 \n",
            "Accuracy of the network on the test samples:18.48359398957375\n",
            "epoch is 64 loss validation set is 0.026128622568739372\n",
            "loss is 0.022240723030907766\n",
            "Accuracy of the network on the train samples: 57.857142857142854 \n",
            "Accuracy of the network on the test samples:18.061944188899112\n",
            "epoch is 65 loss validation set is 0.02634808588378892\n",
            "loss is 0.022191579001290457\n",
            "Accuracy of the network on the train samples: 55.714285714285715 \n",
            "Accuracy of the network on the test samples:17.82428702851886\n",
            "epoch is 66 loss validation set is 0.026422782311297677\n",
            "loss is 0.021117516926356723\n",
            "Accuracy of the network on the train samples: 56.42857142857143 \n",
            "Accuracy of the network on the test samples:18.16160686905857\n",
            "epoch is 67 loss validation set is 0.02652385517411055\n",
            "loss is 0.022397281442369733\n",
            "Accuracy of the network on the train samples: 57.857142857142854 \n",
            "Accuracy of the network on the test samples:18.130941429009507\n",
            "epoch is 68 loss validation set is 0.026695789697893338\n",
            "loss is 0.020626839569636752\n",
            "Accuracy of the network on the train samples: 58.57142857142857 \n",
            "Accuracy of the network on the test samples:17.939282428702853\n",
            "epoch is 69 loss validation set is 0.026839132361600678\n",
            "loss is 0.02028942108154297\n",
            "Accuracy of the network on the train samples: 57.142857142857146 \n",
            "Accuracy of the network on the test samples:17.670959828273535\n",
            "epoch is 70 loss validation set is 0.026985334439790894\n",
            "loss is 0.02080685496330261\n",
            "Accuracy of the network on the train samples: 57.857142857142854 \n",
            "Accuracy of the network on the test samples:18.115608708984976\n",
            "epoch is 71 loss validation set is 0.026946262050647377\n",
            "loss is 0.02008170911243984\n",
            "Accuracy of the network on the train samples: 60.0 \n",
            "Accuracy of the network on the test samples:18.452928549524685\n",
            "epoch is 72 loss validation set is 0.026977973512914494\n",
            "loss is 0.02005247644015721\n",
            "Accuracy of the network on the train samples: 57.142857142857146 \n",
            "Accuracy of the network on the test samples:18.276602269242563\n",
            "epoch is 73 loss validation set is 0.02701782617273597\n",
            "loss is 0.02052021196910313\n",
            "Accuracy of the network on the train samples: 59.285714285714285 \n",
            "Accuracy of the network on the test samples:18.44526218951242\n",
            "epoch is 74 loss validation set is 0.02713201743113925\n",
            "loss is 0.019659256083624704\n",
            "Accuracy of the network on the train samples: 57.857142857142854 \n",
            "Accuracy of the network on the test samples:18.031278748850045\n",
            "epoch is 75 loss validation set is 0.02717902531692566\n",
            "loss is 0.01974071775163923\n",
            "Accuracy of the network on the train samples: 60.714285714285715 \n",
            "Accuracy of the network on the test samples:17.969947868751916\n",
            "epoch is 76 loss validation set is 0.027375234357786486\n",
            "loss is 0.021776703425816127\n",
            "Accuracy of the network on the train samples: 52.857142857142854 \n",
            "Accuracy of the network on the test samples:17.686292548298066\n",
            "epoch is 77 loss validation set is 0.027376706872166246\n",
            "loss is 0.019287869759968348\n",
            "Accuracy of the network on the train samples: 64.28571428571429 \n",
            "Accuracy of the network on the test samples:17.52529898804048\n",
            "epoch is 78 loss validation set is 0.02744059234044187\n",
            "loss is 0.019923813853945052\n",
            "Accuracy of the network on the train samples: 62.142857142857146 \n",
            "Accuracy of the network on the test samples:17.90095062864152\n",
            "epoch is 79 loss validation set is 0.027455612071194336\n",
            "loss is 0.019603141716548374\n",
            "Accuracy of the network on the train samples: 60.714285714285715 \n",
            "Accuracy of the network on the test samples:18.069610548911378\n",
            "epoch is 80 loss validation set is 0.027537948238597402\n",
            "loss is 0.018108007737568446\n",
            "Accuracy of the network on the train samples: 65.71428571428571 \n",
            "Accuracy of the network on the test samples:18.03894510886231\n",
            "epoch is 81 loss validation set is 0.027612323886739152\n",
            "loss is 0.01990796753338405\n",
            "Accuracy of the network on the train samples: 62.857142857142854 \n",
            "Accuracy of the network on the test samples:18.452928549524685\n",
            "epoch is 82 loss validation set is 0.02764139377204453\n",
            "loss is 0.01931898423603603\n",
            "Accuracy of the network on the train samples: 67.14285714285714 \n",
            "Accuracy of the network on the test samples:18.092609628948175\n",
            "epoch is 83 loss validation set is 0.02787519310998317\n",
            "loss is 0.018718011038643973\n",
            "Accuracy of the network on the train samples: 63.57142857142857 \n",
            "Accuracy of the network on the test samples:18.031278748850045\n",
            "epoch is 84 loss validation set is 0.02786085308420625\n",
            "loss is 0.018554967641830445\n",
            "Accuracy of the network on the train samples: 67.85714285714286 \n",
            "Accuracy of the network on the test samples:18.38393130941429\n",
            "epoch is 85 loss validation set is 0.027858699768169348\n",
            "loss is 0.019900834560394286\n",
            "Accuracy of the network on the train samples: 62.857142857142854 \n",
            "Accuracy of the network on the test samples:18.452928549524685\n",
            "epoch is 86 loss validation set is 0.028085071775160914\n",
            "loss is 0.018101114886147636\n",
            "Accuracy of the network on the train samples: 67.14285714285714 \n",
            "Accuracy of the network on the test samples:18.215271389144434\n",
            "epoch is 87 loss validation set is 0.028172664483680714\n",
            "loss is 0.018420472315379553\n",
            "Accuracy of the network on the train samples: 65.71428571428571 \n",
            "Accuracy of the network on the test samples:17.785955228457528\n",
            "epoch is 88 loss validation set is 0.028516046750841607\n",
            "loss is 0.017294064589909144\n",
            "Accuracy of the network on the train samples: 67.14285714285714 \n",
            "Accuracy of the network on the test samples:17.977614228764182\n",
            "epoch is 89 loss validation set is 0.028652330934178863\n",
            "loss is 0.01860610672405788\n",
            "Accuracy of the network on the train samples: 62.142857142857146 \n",
            "Accuracy of the network on the test samples:17.19564550751303\n",
            "epoch is 90 loss validation set is 0.028794559917724852\n",
            "loss is 0.01717834642955235\n",
            "Accuracy of the network on the train samples: 70.0 \n",
            "Accuracy of the network on the test samples:18.08494326893591\n",
            "epoch is 91 loss validation set is 0.028610633582799794\n",
            "loss is 0.016864338091441562\n",
            "Accuracy of the network on the train samples: 71.42857142857143 \n",
            "Accuracy of the network on the test samples:18.08494326893591\n",
            "epoch is 92 loss validation set is 0.02871006802158537\n",
            "loss is 0.017139890364238193\n",
            "Accuracy of the network on the train samples: 64.28571428571429 \n",
            "Accuracy of the network on the test samples:18.429929469487888\n",
            "epoch is 93 loss validation set is 0.028855201657730097\n",
            "loss is 0.01694888642856053\n",
            "Accuracy of the network on the train samples: 69.28571428571429 \n",
            "Accuracy of the network on the test samples:18.50659306961055\n",
            "epoch is 94 loss validation set is 0.028907328432814836\n",
            "loss is 0.01747937457902091\n",
            "Accuracy of the network on the train samples: 67.85714285714286 \n",
            "Accuracy of the network on the test samples:18.115608708984976\n",
            "epoch is 95 loss validation set is 0.0290275748358735\n",
            "loss is 0.016047229937144688\n",
            "Accuracy of the network on the train samples: 70.0 \n",
            "Accuracy of the network on the test samples:18.422263109475622\n",
            "epoch is 96 loss validation set is 0.029138367276950614\n",
            "loss is 0.0158899188041687\n",
            "Accuracy of the network on the train samples: 68.57142857142857 \n",
            "Accuracy of the network on the test samples:18.268935909230297\n",
            "epoch is 97 loss validation set is 0.029181279641870558\n",
            "loss is 0.01648009249142238\n",
            "Accuracy of the network on the train samples: 72.14285714285714 \n",
            "Accuracy of the network on the test samples:18.192272309107636\n",
            "epoch is 98 loss validation set is 0.029328501542555487\n",
            "loss is 0.01571710365159171\n",
            "Accuracy of the network on the train samples: 70.0 \n",
            "Accuracy of the network on the test samples:18.698252069917203\n",
            "epoch is 99 loss validation set is 0.029229263665668075\n",
            "loss is 0.01626160570553371\n",
            "Accuracy of the network on the train samples: 72.85714285714286 \n",
            "Accuracy of the network on the test samples:18.238270469181234\n",
            "epoch is 100 loss validation set is 0.029377740974332687\n",
            "loss is 0.01529811109815325\n",
            "Accuracy of the network on the train samples: 70.71428571428571 \n",
            "Accuracy of the network on the test samples:18.713584789941734\n",
            "epoch is 101 loss validation set is 0.029478507460863522\n",
            "loss is 0.0152340510061809\n",
            "Accuracy of the network on the train samples: 75.71428571428571 \n",
            "Accuracy of the network on the test samples:18.44526218951242\n",
            "epoch is 102 loss validation set is 0.02974449688947409\n",
            "loss is 0.015662723779678346\n",
            "Accuracy of the network on the train samples: 72.14285714285714 \n",
            "Accuracy of the network on the test samples:18.337933149340692\n",
            "epoch is 103 loss validation set is 0.02984094482665777\n",
            "loss is 0.014764621428080967\n",
            "Accuracy of the network on the train samples: 72.14285714285714 \n",
            "Accuracy of the network on the test samples:17.86261882858019\n",
            "epoch is 104 loss validation set is 0.030046736305749187\n",
            "loss is 0.015680272238595146\n",
            "Accuracy of the network on the train samples: 69.28571428571429 \n",
            "Accuracy of the network on the test samples:18.138607789021773\n",
            "epoch is 105 loss validation set is 0.030191124582246782\n",
            "loss is 0.015204939671925136\n",
            "Accuracy of the network on the train samples: 70.0 \n",
            "Accuracy of the network on the test samples:17.923949708678318\n",
            "epoch is 106 loss validation set is 0.0303604674463585\n",
            "loss is 0.01574096041066306\n",
            "Accuracy of the network on the train samples: 71.42857142857143 \n",
            "Accuracy of the network on the test samples:18.16160686905857\n",
            "epoch is 107 loss validation set is 0.030349044977467106\n",
            "loss is 0.014023129854883467\n",
            "Accuracy of the network on the train samples: 77.14285714285714 \n",
            "Accuracy of the network on the test samples:18.2459368291935\n",
            "epoch is 108 loss validation set is 0.030531854780858663\n",
            "loss is 0.014971237097467695\n",
            "Accuracy of the network on the train samples: 75.0 \n",
            "Accuracy of the network on the test samples:17.847286108555657\n",
            "epoch is 109 loss validation set is 0.0305598948638668\n",
            "loss is 0.01471015555518014\n",
            "Accuracy of the network on the train samples: 71.42857142857143 \n",
            "Accuracy of the network on the test samples:18.215271389144434\n",
            "epoch is 110 loss validation set is 0.03070858856608845\n",
            "loss is 0.015445459740502494\n",
            "Accuracy of the network on the train samples: 75.0 \n",
            "Accuracy of the network on the test samples:18.353265869365224\n",
            "epoch is 111 loss validation set is 0.03074341698023338\n",
            "loss is 0.014837437442370824\n",
            "Accuracy of the network on the train samples: 74.28571428571429 \n",
            "Accuracy of the network on the test samples:18.698252069917203\n",
            "epoch is 112 loss validation set is 0.03079078554631888\n",
            "loss is 0.01410764924117497\n",
            "Accuracy of the network on the train samples: 71.42857142857143 \n",
            "Accuracy of the network on the test samples:18.44526218951242\n",
            "epoch is 113 loss validation set is 0.030857088137389473\n",
            "loss is 0.013026450787271772\n",
            "Accuracy of the network on the train samples: 75.71428571428571 \n",
            "Accuracy of the network on the test samples:18.061944188899112\n",
            "epoch is 114 loss validation set is 0.031133231941961284\n",
            "loss is 0.014175564476421902\n",
            "Accuracy of the network on the train samples: 72.14285714285714 \n",
            "Accuracy of the network on the test samples:18.253603189205766\n",
            "epoch is 115 loss validation set is 0.031321360139311624\n",
            "loss is 0.014355230331420898\n",
            "Accuracy of the network on the train samples: 74.28571428571429 \n",
            "Accuracy of the network on the test samples:17.808954308494325\n",
            "epoch is 116 loss validation set is 0.03143642026198784\n",
            "loss is 0.01355860275881631\n",
            "Accuracy of the network on the train samples: 75.0 \n",
            "Accuracy of the network on the test samples:17.96228150873965\n",
            "epoch is 117 loss validation set is 0.03172957268422164\n",
            "loss is 0.01357710531779698\n",
            "Accuracy of the network on the train samples: 75.71428571428571 \n",
            "Accuracy of the network on the test samples:17.954615148727385\n",
            "epoch is 118 loss validation set is 0.031703061941977986\n",
            "loss is 0.012492117711475917\n",
            "Accuracy of the network on the train samples: 75.71428571428571 \n",
            "Accuracy of the network on the test samples:17.793621588469794\n",
            "epoch is 119 loss validation set is 0.0317139266020533\n",
            "loss is 0.016557606628962926\n",
            "Accuracy of the network on the train samples: 71.42857142857143 \n",
            "Accuracy of the network on the test samples:18.061944188899112\n",
            "epoch is 120 loss validation set is 0.031811395714305656\n",
            "loss is 0.013991984724998473\n",
            "Accuracy of the network on the train samples: 74.28571428571429 \n",
            "Accuracy of the network on the test samples:18.613922109782276\n",
            "epoch is 121 loss validation set is 0.031718765581652125\n",
            "loss is 0.01309102007320949\n",
            "Accuracy of the network on the train samples: 76.42857142857143 \n",
            "Accuracy of the network on the test samples:18.253603189205766\n",
            "epoch is 122 loss validation set is 0.031780390131148195\n",
            "loss is 0.012868710926600866\n",
            "Accuracy of the network on the train samples: 77.85714285714286 \n",
            "Accuracy of the network on the test samples:18.422263109475622\n",
            "epoch is 123 loss validation set is 0.03178729670283912\n",
            "loss is 0.012419711266245161\n",
            "Accuracy of the network on the train samples: 77.85714285714286 \n",
            "Accuracy of the network on the test samples:18.276602269242563\n",
            "epoch is 124 loss validation set is 0.03170293383128948\n",
            "loss is 0.01217544674873352\n",
            "Accuracy of the network on the train samples: 75.0 \n",
            "Accuracy of the network on the test samples:18.437595829500154\n",
            "epoch is 125 loss validation set is 0.03198883945464503\n",
            "loss is 0.013013288804462978\n",
            "Accuracy of the network on the train samples: 76.42857142857143 \n",
            "Accuracy of the network on the test samples:18.437595829500154\n",
            "epoch is 126 loss validation set is 0.03206707752397988\n",
            "loss is 0.012170786091259548\n",
            "Accuracy of the network on the train samples: 80.71428571428571 \n",
            "Accuracy of the network on the test samples:18.537258509659612\n",
            "epoch is 127 loss validation set is 0.03240586473180706\n",
            "loss is 0.011828285029956273\n",
            "Accuracy of the network on the train samples: 80.71428571428571 \n",
            "Accuracy of the network on the test samples:18.475927629561482\n",
            "epoch is 128 loss validation set is 0.03269257912128405\n",
            "loss is 0.013909680502755302\n",
            "Accuracy of the network on the train samples: 73.57142857142857 \n",
            "Accuracy of the network on the test samples:18.537258509659612\n",
            "epoch is 129 loss validation set is 0.0326982454009233\n",
            "loss is 0.011001312306949071\n",
            "Accuracy of the network on the train samples: 84.28571428571429 \n",
            "Accuracy of the network on the test samples:18.39926402943882\n",
            "epoch is 130 loss validation set is 0.0327032245547082\n",
            "loss is 0.012954539912087577\n",
            "Accuracy of the network on the train samples: 79.28571428571429 \n",
            "Accuracy of the network on the test samples:18.345599509352958\n",
            "epoch is 131 loss validation set is 0.032661956024111434\n",
            "loss is 0.013480178373200553\n",
            "Accuracy of the network on the train samples: 75.0 \n",
            "Accuracy of the network on the test samples:18.176939589083105\n",
            "epoch is 132 loss validation set is 0.032669044809449634\n",
            "loss is 0.012091481259890966\n",
            "Accuracy of the network on the train samples: 77.14285714285714 \n",
            "Accuracy of the network on the test samples:18.230604109168965\n",
            "epoch is 134 loss validation set is 0.0328449646193204\n",
            "loss is 0.011168771130698068\n",
            "Accuracy of the network on the train samples: 82.85714285714286 \n",
            "Accuracy of the network on the test samples:17.755289788408465\n",
            "epoch is 135 loss validation set is 0.032932815980194756\n",
            "loss is 0.012329786590167454\n",
            "Accuracy of the network on the train samples: 79.28571428571429 \n",
            "Accuracy of the network on the test samples:17.83961974854339\n",
            "epoch is 136 loss validation set is 0.03308574853956754\n",
            "loss is 0.011236557790211269\n",
            "Accuracy of the network on the train samples: 79.28571428571429 \n",
            "Accuracy of the network on the test samples:17.7246243483594\n",
            "epoch is 137 loss validation set is 0.03343387298589833\n",
            "loss is 0.012348289149148123\n",
            "Accuracy of the network on the train samples: 82.85714285714286 \n",
            "Accuracy of the network on the test samples:17.655627108249003\n",
            "epoch is 138 loss validation set is 0.033698856355368234\n",
            "loss is 0.011447385804993765\n",
            "Accuracy of the network on the train samples: 80.0 \n",
            "Accuracy of the network on the test samples:17.785955228457528\n",
            "epoch is 139 loss validation set is 0.03362953714050789\n",
            "loss is 0.012108314037322997\n",
            "Accuracy of the network on the train samples: 82.14285714285714 \n",
            "Accuracy of the network on the test samples:17.908616988653787\n",
            "epoch is 140 loss validation set is 0.0337147530292814\n",
            "loss is 0.010373076796531678\n",
            "Accuracy of the network on the train samples: 81.42857142857143 \n",
            "Accuracy of the network on the test samples:18.192272309107636\n",
            "epoch is 141 loss validation set is 0.033860319306315986\n",
            "loss is 0.012397960679871695\n",
            "Accuracy of the network on the train samples: 80.0 \n",
            "Accuracy of the network on the test samples:17.96228150873965\n",
            "epoch is 142 loss validation set is 0.03382926091793965\n",
            "loss is 0.010481269444738116\n",
            "Accuracy of the network on the train samples: 80.0 \n",
            "Accuracy of the network on the test samples:18.18460594909537\n",
            "epoch is 143 loss validation set is 0.0339522990885047\n",
            "loss is 0.009569671750068665\n",
            "Accuracy of the network on the train samples: 85.71428571428571 \n",
            "Accuracy of the network on the test samples:18.230604109168965\n",
            "epoch is 144 loss validation set is 0.03389046642539765\n",
            "loss is 0.009774091839790344\n",
            "Accuracy of the network on the train samples: 85.71428571428571 \n",
            "Accuracy of the network on the test samples:17.94694878871512\n",
            "epoch is 145 loss validation set is 0.03418671711936607\n",
            "loss is 0.010667534385408675\n",
            "Accuracy of the network on the train samples: 82.14285714285714 \n",
            "Accuracy of the network on the test samples:18.03894510886231\n",
            "epoch is 146 loss validation set is 0.03426394625991007\n",
            "loss is 0.010182748096329824\n",
            "Accuracy of the network on the train samples: 86.42857142857143 \n",
            "Accuracy of the network on the test samples:17.82428702851886\n",
            "epoch is 147 loss validation set is 0.034524787042594984\n",
            "loss is 0.009381046891212464\n",
            "Accuracy of the network on the train samples: 87.14285714285714 \n",
            "Accuracy of the network on the test samples:17.908616988653787\n",
            "epoch is 148 loss validation set is 0.03462182051636112\n",
            "loss is 0.011214305247579302\n",
            "Accuracy of the network on the train samples: 79.28571428571429 \n",
            "Accuracy of the network on the test samples:17.793621588469794\n",
            "epoch is 149 loss validation set is 0.03469852324973875\n",
            "loss is 0.009901152764047896\n",
            "Accuracy of the network on the train samples: 82.85714285714286 \n",
            "Accuracy of the network on the test samples:17.816620668506594\n",
            "epoch is 150 loss validation set is 0.03468182088041262\n",
            "loss is 0.009626144596508571\n",
            "Accuracy of the network on the train samples: 85.0 \n",
            "Accuracy of the network on the test samples:18.046611468874577\n",
            "epoch is 151 loss validation set is 0.034582749059396956\n",
            "loss is 0.01003883523600442\n",
            "Accuracy of the network on the train samples: 83.57142857142857 \n",
            "Accuracy of the network on the test samples:18.468261269549217\n",
            "epoch is 152 loss validation set is 0.034704825750928245\n",
            "loss is 0.011609101295471191\n",
            "Accuracy of the network on the train samples: 80.71428571428571 \n",
            "Accuracy of the network on the test samples:18.253603189205766\n",
            "epoch is 153 loss validation set is 0.03486779777230898\n",
            "loss is 0.01291558699948447\n",
            "Accuracy of the network on the train samples: 78.57142857142857 \n",
            "Accuracy of the network on the test samples:18.590923029745476\n",
            "epoch is 154 loss validation set is 0.034971855217530955\n",
            "loss is 0.008887174725532531\n",
            "Accuracy of the network on the train samples: 85.71428571428571 \n",
            "Accuracy of the network on the test samples:18.437595829500154\n",
            "epoch is 155 loss validation set is 0.03498703082329435\n",
            "loss is 0.009286635262625558\n",
            "Accuracy of the network on the train samples: 86.42857142857143 \n",
            "Accuracy of the network on the test samples:18.429929469487888\n",
            "epoch is 156 loss validation set is 0.03524358509801276\n",
            "loss is 0.009338595611708505\n",
            "Accuracy of the network on the train samples: 84.28571428571429 \n",
            "Accuracy of the network on the test samples:18.636921189819073\n",
            "epoch is 157 loss validation set is 0.03529513918596775\n",
            "loss is 0.009536564775875637\n",
            "Accuracy of the network on the train samples: 89.28571428571429 \n",
            "Accuracy of the network on the test samples:18.652253909843605\n",
            "epoch is 158 loss validation set is 0.03549809771715882\n",
            "loss is 0.008738002181053162\n",
            "Accuracy of the network on the train samples: 84.28571428571429 \n",
            "Accuracy of the network on the test samples:18.276602269242563\n",
            "epoch is 159 loss validation set is 0.03549369996912236\n",
            "loss is 0.009177305442946298\n",
            "Accuracy of the network on the train samples: 87.14285714285714 \n",
            "Accuracy of the network on the test samples:18.230604109168965\n",
            "epoch is 160 loss validation set is 0.03541735904928147\n",
            "loss is 0.007999302659715926\n",
            "Accuracy of the network on the train samples: 85.71428571428571 \n",
            "Accuracy of the network on the test samples:17.532965348052745\n",
            "epoch is 161 loss validation set is 0.03554493974813176\n",
            "loss is 0.008448692304747445\n",
            "Accuracy of the network on the train samples: 87.85714285714286 \n",
            "Accuracy of the network on the test samples:18.414596749463353\n",
            "epoch is 162 loss validation set is 0.035396080136262574\n",
            "loss is 0.00938741649900164\n",
            "Accuracy of the network on the train samples: 87.85714285714286 \n",
            "Accuracy of the network on the test samples:18.169273229070836\n",
            "epoch is 163 loss validation set is 0.0358995444311828\n",
            "loss is 0.009405995266778128\n",
            "Accuracy of the network on the train samples: 85.71428571428571 \n",
            "Accuracy of the network on the test samples:18.291934989267094\n",
            "epoch is 164 loss validation set is 0.03580683160873689\n",
            "loss is 0.0091103589960507\n",
            "Accuracy of the network on the train samples: 87.14285714285714 \n",
            "Accuracy of the network on the test samples:18.253603189205766\n",
            "epoch is 165 loss validation set is 0.03621287738498242\n",
            "loss is 0.008612090349197387\n",
            "Accuracy of the network on the train samples: 85.71428571428571 \n",
            "Accuracy of the network on the test samples:17.992946948788717\n",
            "epoch is 166 loss validation set is 0.0365852495893603\n",
            "loss is 0.009253938283239092\n",
            "Accuracy of the network on the train samples: 87.14285714285714 \n",
            "Accuracy of the network on the test samples:18.061944188899112\n",
            "epoch is 167 loss validation set is 0.036727550734555345\n",
            "loss is 0.00910476062979017\n",
            "Accuracy of the network on the train samples: 85.0 \n",
            "Accuracy of the network on the test samples:17.923949708678318\n",
            "epoch is 168 loss validation set is 0.03687276621970323\n",
            "loss is 0.008272798572267806\n",
            "Accuracy of the network on the train samples: 88.57142857142857 \n",
            "Accuracy of the network on the test samples:18.16160686905857\n",
            "epoch is 169 loss validation set is 0.036754117919345165\n",
            "loss is 0.008390451541968755\n",
            "Accuracy of the network on the train samples: 90.0 \n",
            "Accuracy of the network on the test samples:17.83961974854339\n",
            "epoch is 170 loss validation set is 0.03689337328729802\n",
            "loss is 0.007849495112895965\n",
            "Accuracy of the network on the train samples: 90.0 \n",
            "Accuracy of the network on the test samples:18.68291934989267\n",
            "epoch is 171 loss validation set is 0.03675699398511029\n",
            "loss is 0.0077587625810078215\n",
            "Accuracy of the network on the train samples: 89.28571428571429 \n",
            "Accuracy of the network on the test samples:18.50659306961055\n",
            "epoch is 172 loss validation set is 0.036561890472410936\n",
            "loss is 0.00795517201934542\n",
            "Accuracy of the network on the train samples: 88.57142857142857 \n",
            "Accuracy of the network on the test samples:18.46059490953695\n",
            "epoch is 173 loss validation set is 0.03659328475608229\n",
            "loss is 0.008172521846635\n",
            "Accuracy of the network on the train samples: 90.0 \n",
            "Accuracy of the network on the test samples:18.18460594909537\n",
            "epoch is 174 loss validation set is 0.03678134684181038\n",
            "loss is 0.008755486564976829\n",
            "Accuracy of the network on the train samples: 91.42857142857143 \n",
            "Accuracy of the network on the test samples:18.268935909230297\n",
            "epoch is 175 loss validation set is 0.03688747922689115\n",
            "loss is 0.00803771870476859\n",
            "Accuracy of the network on the train samples: 87.85714285714286 \n",
            "Accuracy of the network on the test samples:17.977614228764182\n",
            "epoch is 176 loss validation set is 0.037244411214514404\n",
            "loss is 0.009099186531135015\n",
            "Accuracy of the network on the train samples: 87.85714285714286 \n",
            "Accuracy of the network on the test samples:17.893284268629255\n",
            "epoch is 177 loss validation set is 0.0374708789983654\n",
            "loss is 0.007770818471908569\n",
            "Accuracy of the network on the train samples: 90.0 \n",
            "Accuracy of the network on the test samples:17.640294388224472\n",
            "epoch is 178 loss validation set is 0.03784240125622789\n",
            "loss is 0.008092151582241058\n",
            "Accuracy of the network on the train samples: 88.57142857142857 \n",
            "Accuracy of the network on the test samples:18.115608708984976\n",
            "epoch is 179 loss validation set is 0.03772239162672593\n",
            "loss is 0.0073366037436894006\n",
            "Accuracy of the network on the train samples: 90.71428571428571 \n",
            "Accuracy of the network on the test samples:18.12327506899724\n",
            "epoch is 180 loss validation set is 0.03806079572711536\n",
            "loss is 0.009403903143746513\n",
            "Accuracy of the network on the train samples: 89.28571428571429 \n",
            "Accuracy of the network on the test samples:18.061944188899112\n",
            "epoch is 181 loss validation set is 0.03777774549707683\n",
            "loss is 0.00786298598561968\n",
            "Accuracy of the network on the train samples: 90.0 \n",
            "Accuracy of the network on the test samples:17.7246243483594\n",
            "epoch is 182 loss validation set is 0.03801030922213861\n",
            "loss is 0.008781930804252625\n",
            "Accuracy of the network on the train samples: 89.28571428571429 \n",
            "Accuracy of the network on the test samples:17.893284268629255\n",
            "epoch is 183 loss validation set is 0.03804959614048045\n",
            "loss is 0.011615656954901559\n",
            "Accuracy of the network on the train samples: 85.0 \n",
            "Accuracy of the network on the test samples:18.046611468874577\n",
            "epoch is 184 loss validation set is 0.038096399732763436\n",
            "loss is 0.008176582838807787\n",
            "Accuracy of the network on the train samples: 90.0 \n",
            "Accuracy of the network on the test samples:17.7016252683226\n",
            "epoch is 185 loss validation set is 0.03805986767859226\n",
            "loss is 0.006813127228191921\n",
            "Accuracy of the network on the train samples: 93.57142857142857 \n",
            "Accuracy of the network on the test samples:17.94694878871512\n",
            "epoch is 186 loss validation set is 0.03796451042781246\n",
            "loss is 0.007252675082002368\n",
            "Accuracy of the network on the train samples: 88.57142857142857 \n",
            "Accuracy of the network on the test samples:18.215271389144434\n",
            "epoch is 187 loss validation set is 0.03787361835270928\n",
            "loss is 0.006940178998879024\n",
            "Accuracy of the network on the train samples: 92.85714285714286 \n",
            "Accuracy of the network on the test samples:17.808954308494325\n",
            "epoch is 188 loss validation set is 0.0382370603336801\n",
            "loss is 0.0075798430613109044\n",
            "Accuracy of the network on the train samples: 88.57142857142857 \n",
            "Accuracy of the network on the test samples:17.73995706838393\n",
            "epoch is 189 loss validation set is 0.038606723094783434\n",
            "loss is 0.008037789378847394\n",
            "Accuracy of the network on the train samples: 87.14285714285714 \n",
            "Accuracy of the network on the test samples:17.877951548604724\n",
            "epoch is 190 loss validation set is 0.03876785554245402\n",
            "loss is 0.0078002806220735825\n",
            "Accuracy of the network on the train samples: 90.71428571428571 \n",
            "Accuracy of the network on the test samples:17.86261882858019\n",
            "epoch is 191 loss validation set is 0.03903433250086836\n",
            "loss is 0.0075998459543500626\n",
            "Accuracy of the network on the train samples: 90.71428571428571 \n",
            "Accuracy of the network on the test samples:17.594296228150874\n",
            "epoch is 192 loss validation set is 0.03913685141147846\n",
            "loss is 0.007630649847643716\n",
            "Accuracy of the network on the train samples: 89.28571428571429 \n",
            "Accuracy of the network on the test samples:17.808954308494325\n",
            "epoch is 193 loss validation set is 0.03902457579993207\n",
            "loss is 0.007273771294525691\n",
            "Accuracy of the network on the train samples: 88.57142857142857 \n",
            "Accuracy of the network on the test samples:17.509966268015948\n",
            "epoch is 194 loss validation set is 0.038902547801063676\n",
            "loss is 0.006819582198347364\n",
            "Accuracy of the network on the train samples: 92.14285714285714 \n",
            "Accuracy of the network on the test samples:17.76295614842073\n",
            "epoch is 195 loss validation set is 0.03892956425974757\n",
            "loss is 0.010414035831178938\n",
            "Accuracy of the network on the train samples: 85.0 \n",
            "Accuracy of the network on the test samples:18.192272309107636\n",
            "epoch is 196 loss validation set is 0.038899699042670315\n",
            "loss is 0.007269216861043658\n",
            "Accuracy of the network on the train samples: 90.71428571428571 \n",
            "Accuracy of the network on the test samples:17.66329346826127\n",
            "epoch is 197 loss validation set is 0.03913745369073329\n",
            "loss is 0.007550127378531865\n",
            "Accuracy of the network on the train samples: 87.85714285714286 \n",
            "Accuracy of the network on the test samples:17.647960748236738\n",
            "epoch is 198 loss validation set is 0.039242873762839046\n",
            "loss is 0.0068237447312899996\n",
            "Accuracy of the network on the train samples: 93.57142857142857 \n",
            "Accuracy of the network on the test samples:17.785955228457528\n",
            "epoch is 199 loss validation set is 0.03950192552883543\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rct7EmUMGzHI",
        "outputId": "ff9cc240-f4de-4ee0-cbaa-7da64f3fb84b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorboard --logdir /content/logs/tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OlV5dgdfHKz",
        "colab_type": "text"
      },
      "source": [
        "# The Classification Dataset Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCnOhz2Yg3T6",
        "colab_type": "code",
        "outputId": "7559ef66-a9b6-46a5-ea7a-8c856560c006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# First load the best model based on the classification scenario above\n",
        "net = ClassificationNet(embedding_network=model, num_classes=num_classes)\n",
        "PATH = '/content/126-classifier.pth'\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "net.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassificationNet(\n",
              "  (embedding_network): TripletNetwork(\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "      (6): Linear(in_features=256, out_features=64, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (nonlinear): ReLU()\n",
              "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=23, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsGspogEg3dW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Still not ready. Please refer to the KNN part for now\n",
        "all_labels = []\n",
        "all_predictions=[]\n",
        "with torch.no_grad():\n",
        "    for data in classification_test_loader:\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.cuda()\n",
        "        batch_size = inputs.shape[0]\n",
        "        inputs = inputs.reshape(batch_size,-1)\n",
        "        # Next the evaluation\n",
        "        outputs = net(inputs)\n",
        "        labels = labels.cuda()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss_val = loss_val + loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        for idx in range(batch_size):\n",
        "            all_predictions.append(predicted[idx].item())\n",
        "            all_labels.append(labels[idx].item())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7IOcTdmFInnH",
        "colab": {}
      },
      "source": [
        "labels = list(set(train_df.labels_encoded))\n",
        "cm = confusion_matrix(all_labels, all_predictions, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JClpBpSJK-sD",
        "outputId": "1b9b0bd9-0846-4a86-b6b4-d651b0665213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "plt.title('Confusion matrix of the classifier')\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + get_all_labels())\n",
        "ax.set_yticklabels([''] + get_all_labels())\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAEQCAYAAAAnG6RcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSAagJGlIBqAkaUhf+vNf8LlrCYMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "83WzcFdcK-sJ",
        "outputId": "78b0fc87-cdca-4165-cb3b-517b920f9099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=False, ax = ax, fmt='g', cmap='Greens'); #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels([''] + get_all_labels());\n",
        "ax.yaxis.set_ticklabels([''] + get_all_labels());"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAFbCAYAAAD1FWSRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sTu_7QLyK-sN",
        "outputId": "627c6413-63b3-46ee-dbe7-6626a3537e00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "print(classification_report(all_labels, all_predictions,labels=labels, target_names=get_all_labels()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                             precision    recall  f1-score   support\n",
            "\n",
            "      Amazon Instant Videos       0.18      0.19      0.18       989\n",
            "               Android Apps       0.21      0.27      0.23       989\n",
            "                 Automotive       0.06      0.18      0.09       392\n",
            "                       Baby       0.17      0.26      0.20       784\n",
            "                     Beauty       0.17      0.22      0.19       989\n",
            "              CDs and Vinyl       0.20      0.19      0.19       989\n",
            "Cell Phones and Accessories       0.29      0.17      0.21       989\n",
            "   Clothing, Shoes, Jewelry       0.13      0.08      0.09       989\n",
            "              Digital Music       0.42      0.37      0.39       989\n",
            "                Electronics       0.29      0.29      0.29       989\n",
            "        Grocery and Gourmet       0.14      0.18      0.16       989\n",
            "   Health and Personal Care       0.12      0.05      0.07       989\n",
            "           Home and Kitchen       0.11      0.05      0.07       989\n",
            "                     Kindle       0.10      0.09      0.10       989\n",
            "\n",
            "                   accuracy                           0.18     13044\n",
            "                  macro avg       0.18      0.18      0.18     13044\n",
            "               weighted avg       0.19      0.18      0.18     13044\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1870: UserWarning: labels size, 14, does not match size of target_names, 23\n",
            "  .format(len(labels), len(target_names))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kLxjnxIfa6U",
        "colab_type": "text"
      },
      "source": [
        "# Now the Nearest Neighbour Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ykFCG_mlxVnE",
        "colab": {}
      },
      "source": [
        "# We need to define a specific dataloader in this case, which shall be frankly, quite simple and dummy\n",
        "class TestDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Train: For each sample (anchor) randomly chooses a positive and negative samples\n",
        "    Test: Creates fixed triplets for testing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, select_column):\n",
        "         \n",
        "        \n",
        "        self.dataset = dataset\n",
        "        self.train_labels = self.dataset.labels_encoded\n",
        "            # Drop the labels column so that remaining features form part of the training set\n",
        "        self.dataset = self.dataset.drop('labels_encoded', axis=1)\n",
        "        self.train_data = self.dataset\n",
        "        self.select_column = select_column\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        #print(type(self.train_data))\n",
        "        selected_frame, label = self.train_data.iloc[index], self.train_labels.iloc[index]\n",
        "        str_data = selected_frame[self.select_column]\n",
        "\n",
        "        return str_data, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1bcxIkQnx40i",
        "colab": {}
      },
      "source": [
        "# Global declarations\n",
        "batch_size = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5lRDgP4N7U4l",
        "colab": {}
      },
      "source": [
        "one_shot_train_dataset = SoftmaxDataset(dataset=train_df,select_column='sentence_embedding')\n",
        "one_shot_test_dataset = SoftmaxDataset(dataset=test_df,select_column='sentence_embedding')\n",
        "# Now the dataloaders need to be defined as well\n",
        "one_shot_train_loader = DataLoader(one_shot_train_dataset, batch_size=batch_size,shuffle=True)\n",
        "one_shot_test_loader = DataLoader(one_shot_test_dataset, batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0534e5c8-c147-4f9f-b8ae-81e964b64502",
        "id": "ZTNsLHmDvmAP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Load a pre-existing model \n",
        "PATH = '/content/11-model-GOOD.pth'\n",
        "model = TripletNetwork()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.cuda()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TripletNetwork(\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=256, out_features=64, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ppZ_kSqnzkTK",
        "colab": {}
      },
      "source": [
        "embedding_model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "19dhXYv79Ndg",
        "colab": {}
      },
      "source": [
        "# Let us save the embedding of all elements in the train_data as well as their index\n",
        "# this can be used later for our purpose\n",
        "embedding_space_one_shot = []\n",
        "for i, data in enumerate(one_shot_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.cuda()\n",
        "        batch_size = inputs.shape[0]\n",
        "        inputs = inputs.reshape(batch_size,-1)\n",
        "        labels = labels.cuda()\n",
        "        embeddings = embedding_model.fc(inputs)\n",
        "        for index,tensor in enumerate(embeddings):\n",
        "           embedding_space_one_shot.append((labels[index],tensor))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "63585d0f-b385-4045-f617-ceaf333164f4",
        "id": "fI6UTX2w9Ndv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train = []\n",
        "dist = []\n",
        "for index,space in embedding_space_one_shot[:-1]:\n",
        "  dist.append(space)\n",
        "  y_train.append(index.item())\n",
        "# dist = [space for index,space in embedding_space_one_shot[:-1]]\n",
        "result = torch.stack(dist, dim=0)\n",
        "result.shape"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GlmGHMbl15lJ",
        "colab": {}
      },
      "source": [
        "#select the norm\n",
        "def select_norm(vector_x, power=2):\n",
        "  return torch.norm(vector_x,p=power,dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpFLKZlxyGEG",
        "colab": {}
      },
      "source": [
        "def k_nearest_neighbour(distance_embeddings, vector, k=5):  \n",
        "    updated_result = select_norm(vector_x=(distance_embeddings - vector), power=2)\n",
        "    values, indices = torch.topk(updated_result,k=k ,largest=False)\n",
        "    candidate_indexes = []\n",
        "    for index in indices:\n",
        "      candidate_indexes.append((embedding_space_one_shot[index][0]).item())\n",
        "    return Counter(candidate_indexes).most_common(1)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RvfnqzTiyGEK",
        "outputId": "5296e15d-0e68-472e-f1eb-3611664d2814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "all_labels = []\n",
        "all_predictions_one_shot=[]\n",
        "for data in one_shot_test_loader:\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.cuda()\n",
        "    batch_size = inputs.shape[0]\n",
        "    inputs = inputs.reshape(batch_size,-1)\n",
        "    # Next the evaluation\n",
        "    \n",
        "    output = embedding_model.fc(inputs)\n",
        "    for idx,query in enumerate(output):\n",
        "        predicted = k_nearest_neighbour(result, query, 5)\n",
        "#         print(labels[idx])\n",
        "#         print(predicted)\n",
        "        all_predictions_one_shot.append(predicted)\n",
        "        correct += (predicted == labels[idx])\n",
        "        all_labels.append(labels[idx].item())\n",
        "    total += labels.size(0)\n",
        "    correct = correct.cpu().sum()\n",
        "print('Accuracy of the network on the test samples: %d %%' % (\n",
        "        100 * correct /total))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test samples: 12 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M77ure6NE0jp",
        "outputId": "a2b49e29-679a-43d7-864b-e89e6f432e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1_score(all_labels, all_predictions_one_shot, average='micro') "
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12027334851936218"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aVu1tX0aE0j4",
        "outputId": "d4a018c3-9a48-43f6-cbb4-8bb289b044ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "f1_score(all_labels, all_predictions_one_shot, average='macro') "
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10328135298913357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s53zB2QuE0j_",
        "colab": {}
      },
      "source": [
        "labels = list(set(train_df.labels_encoded))\n",
        "cm = confusion_matrix(all_labels, all_predictions_one_shot, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nrb57_FnE0kH",
        "outputId": "48a85e93-9450-46c0-cabe-434e1c33210d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "plt.title('Confusion matrix of the classifier')\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + get_all_labels())\n",
        "ax.set_yticklabels([''] + get_all_labels())\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "#plt.show()\n",
        "plt.savefig('Classifier_confusionMatrix_1_30_acc11_labelsencoded.png', dpi = 200)\n"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAEQCAYAAAAOHFvbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SAKbybszE0kK",
        "outputId": "93ff46f4-91f7-4706-98d8-7901f1d45d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=False, ax = ax, fmt='g', cmap='Greens'); #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels([''] + get_all_labels());\n",
        "ax.yaxis.set_ticklabels([''] + get_all_labels());\n",
        "plt.savefig('ConfusionMatrix_1_30_acc11_labelsencoded.png', dpi = 200)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEXCAYAAABiTcW4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h7wAVfL8E0kN",
        "outputId": "9c1b107d-c542-447d-ff6f-f859b5ead7e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(all_labels, all_predictions_one_shot)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12027334851936218"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nQemngRdE0kT",
        "outputId": "0c958156-bcd0-4e10-fb3b-090b74b8fcda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "print(classification_report(all_labels, all_predictions_one_shot,labels=labels, target_names=get_all_labels()))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            Automotive       0.10      0.02      0.03       998\n",
            "                  Baby       0.10      0.18      0.13       998\n",
            "Digital_Ebook_Purchase       0.02      0.06      0.03       401\n",
            "Digital_Music_Purchase       0.12      0.13      0.13       793\n",
            "Digital_Video_Download       0.10      0.09      0.09       998\n",
            "           Electronics       0.20      0.05      0.07       998\n",
            "                  Home       0.21      0.10      0.13       998\n",
            "           Mobile_Apps       0.17      0.35      0.23       998\n",
            "   Musical Instruments       0.02      0.01      0.02       998\n",
            "                 Shoes       0.27      0.38      0.32       998\n",
            "                Sports       0.14      0.11      0.12       998\n",
            "                  Toys       0.05      0.06      0.06       998\n",
            "                 Video       0.00      0.00      0.00       998\n",
            "             Video DVD       0.08      0.11      0.09       998\n",
            "\n",
            "              accuracy                           0.12     13170\n",
            "             macro avg       0.11      0.12      0.10     13170\n",
            "          weighted avg       0.12      0.12      0.11     13170\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1870: UserWarning: labels size, 14, does not match size of target_names, 15\n",
            "  .format(len(labels), len(target_names))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clHglQjIyRPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}