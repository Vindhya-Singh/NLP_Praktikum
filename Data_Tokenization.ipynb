{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Tokenization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sScywYm8EJhe",
        "outputId": "e84c95b5-2d9d-43f2-ccfe-dd56163352d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wkVYLPcL3iTA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SphmC-tGZeLP"
      },
      "source": [
        "Code for preprocessing the text and other cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pTXhvxZHXRIL"
      },
      "source": [
        "Setting up of the Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j3FwhbOyhwHA"
      },
      "source": [
        "##Extra Section that will come in handy later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_wUDuuzC3knQ"
      },
      "source": [
        "# This is an attempt to include the LASER multi lingual embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mngRKDEg3x2h",
        "outputId": "6aa1c943-be7f-4d03-a6a9-0eafcf0aeb3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/ceshine/LASER.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LASER'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 591 (delta 11), reused 24 (delta 11), pack-reused 560\u001b[K\n",
            "Receiving objects: 100% (591/591), 2.60 MiB | 2.02 MiB/s, done.\n",
            "Resolving deltas: 100% (175/175), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Akm1QeP4lea",
        "outputId": "5ccbe941-121d-4320-d4c6-8bdfff3ebdc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%env LASER=/content/LASER\n",
        "!echo $LASER"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: LASER=/content/LASER\n",
            "/content/LASER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3KxeDCC74lhZ",
        "outputId": "ce5f9a29-04fa-4418-cfbc-983e2529dff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd LASER"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LASER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D7ADRwFZ4lp8",
        "outputId": "31f9118d-73b5-44d6-a52f-ff015846eda2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!bash install_models.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading networks\n",
            " - creating directory /content/LASER/models\n",
            " - bilstm.93langs.2018-12-26.pt\n",
            " - 93langs.fcodes\n",
            " - 93langs.fvocab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U5F_sNpe4lkm",
        "outputId": "af3685b7-34c4-4082-9c58-fbfd53a38b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2247
        }
      },
      "source": [
        "!bash install_external_tools.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing external tools\n",
            " - creating directory /content/LASER/tools-external/moses-tokenizer/tokenizer\n",
            " - download tokenizer/tokenizer.perl\n",
            " - download tokenizer/detokenizer.perl\n",
            " - download tokenizer/normalize-punctuation.perl\n",
            " - download tokenizer/remove-non-printing-char.perl\n",
            " - download tokenizer/deescape-special-chars.perl\n",
            " - download tokenizer/lowercase.perl\n",
            " - download tokenizer/basic-protected-patterns\n",
            " - creating directory /content/LASER/tools-external/moses-tokenizer/share/nonbreaking_prefixes\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ca\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.cs\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.de\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.el\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.en\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.es\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.fi\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.fr\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ga\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.hu\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.is\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.it\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.lt\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.lv\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.nl\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.pl\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.pt\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ro\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ru\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.sk\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.sl\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.sv\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ta\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.yue\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.zh\n",
            " - download fastBPE software from github\n",
            "--2019-06-17 14:32:22--  https://github.com/glample/fastBPE/archive/master.zip\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/glample/fastBPE/zip/master [following]\n",
            "--2019-06-17 14:32:23--  https://codeload.github.com/glample/fastBPE/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.255.120\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.255.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [ <=>                ]   8.88K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-06-17 14:32:23 (90.1 KB/s) - ‘master.zip’ saved [9093]\n",
            "\n",
            "Archive:  master.zip\n",
            "874634b2676d091ced2aa5a2f5917c7106735fa8\n",
            "   creating: fastBPE-master/\n",
            "  inflating: fastBPE-master/LICENSE  \n",
            "  inflating: fastBPE-master/README.md  \n",
            "   creating: fastBPE-master/fastBPE/\n",
            "  inflating: fastBPE-master/fastBPE/fastBPE.hpp  \n",
            "  inflating: fastBPE-master/fastBPE/fastBPE.pyx  \n",
            "  inflating: fastBPE-master/fastBPE/main.cc  \n",
            "  inflating: fastBPE-master/setup.py  \n",
            " - compiling\n",
            "Warning: passing language='c++' to cythonize() is deprecated. Instead, put \"# distutils: language=c++\" in your .pyx or .pxd file(s)\n",
            "Compiling fastBPE/fastBPE.pyx because it changed.\n",
            "[1/1] Cythonizing fastBPE/fastBPE.pyx\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/LASER/tools-external/fastBPE/fastBPE/fastBPE.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating fastBPE.egg-info\n",
            "writing fastBPE.egg-info/PKG-INFO\n",
            "writing dependency_links to fastBPE.egg-info/dependency_links.txt\n",
            "writing requirements to fastBPE.egg-info/requires.txt\n",
            "writing top-level names to fastBPE.egg-info/top_level.txt\n",
            "writing manifest file 'fastBPE.egg-info/SOURCES.txt'\n",
            "package init file 'fastBPE/__init__.py' not found (or not a regular file)\n",
            "reading manifest file 'fastBPE.egg-info/SOURCES.txt'\n",
            "writing manifest file 'fastBPE.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "running build_ext\n",
            "building 'fastBPE' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/fastBPE\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -IfastBPE -I/usr/include/python3.6m -c fastBPE/fastBPE.cpp -o build/temp.linux-x86_64-3.6/fastBPE/fastBPE.o -std=c++11 -Ofast -pthread\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fastBPE/fastBPE.o -o build/lib.linux-x86_64-3.6/fastBPE.cpython-36m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/fastBPE.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for fastBPE.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/fastBPE.py to fastBPE.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fastBPE.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fastBPE.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fastBPE.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fastBPE.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fastBPE.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.fastBPE.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/fastBPE-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing fastBPE-0.0.0-py3.6-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.6/dist-packages/fastBPE-0.0.0-py3.6-linux-x86_64.egg\n",
            "Extracting fastBPE-0.0.0-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding fastBPE 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/fastBPE-0.0.0-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for fastBPE==0.0.0\n",
            "Searching for Cython==0.29.10\n",
            "Best match: Cython 0.29.10\n",
            "Adding Cython 0.29.10 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for fastBPE==0.0.0\n",
            "\n",
            "automatic installation of the Japanese tokenizer mecab may be tricky\n",
            "Please install it manually from https://github.com/taku910/mecab\n",
            "\n",
            "The installation directory should be /content/LASER/tools-external/mecab\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wq9RVwqi8pyM",
        "outputId": "598202d3-265a-4e3c-b30f-c6b89365858a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd tools-external/fastBPE/\n",
        "! g++ -std=c++11 -pthread -O3 fastBPE/main.cc -IfastBPE -o fast"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LASER/tools-external/fastBPE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KpraUBs38jZO",
        "outputId": "545ae26a-13e7-4faf-cfb4-c3f46ecbf20f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd ../../tasks/similarity/\n",
        "! ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LASER/tasks/similarity\n",
            "README.md  wmt.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uVjP99krE02v",
        "outputId": "ee451edd-dcec-4b7f-f891-716276ae8e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "! apt install libopenblas-base libomp-dev"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-base is already the newest version (0.2.20+ds-4).\n",
            "libopenblas-base set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  libomp-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-dev libomp5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 239 kB of archives.\n",
            "After this operation, 804 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n",
            "Fetched 239 kB in 2s (127 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 130912 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Selecting previously unselected package libomp-dev.\n",
            "Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp-dev (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libomp-dev (5.0.1-1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zdgEtRK5AN9g",
        "outputId": "8ee7d224-b2d1-4c71-f2b6-09c21b3f785a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "! pip install faiss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting faiss\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/1c/4ae6cb87cf0c09c25561ea48db11e25713b25c580909902a92c090b377c0/faiss-1.5.3-cp36-cp36m-manylinux1_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from faiss) (1.16.4)\n",
            "Installing collected packages: faiss\n",
            "Successfully installed faiss-1.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lBPIo9wj9GSg",
        "outputId": "fc8e2887-cb2c-42b5-ce74-5e3dbabd9a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        " % cd ./tasks/similarity\n",
        "! bash wmt.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: './tasks/similarity'\n",
            "/content/LASER/tasks/similarity\n",
            " - Download WMT data\n",
            "LASER: similarity search\n",
            "\n",
            "Processing:\n",
            " - loading encoder /content/LASER/models/bilstm.93langs.2018-12-26.pt\n",
            " - transfer encoder to GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9sS0FP2kG-cd",
        "colab": {}
      },
      "source": [
        "# sample feasibility check\n",
        "# % cd ../../source/\n",
        "\n",
        "import os\n",
        "import sys\n",
        "LASER = os.environ['LASER']\n",
        "# now include the extra files in the source\n",
        "sys.path.append(LASER + '/source')\n",
        "sys.path.append(LASER + '/source/lib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "39VFH-l3G-l4",
        "outputId": "d8d894c4-8b00-43aa-eb30-ad612ef467c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "from embed import SentenceEncoder, EncodeLoad, EncodeFile\n",
        "from text_processing import Token, BPEfastApply\n",
        "from indexing import IndexCreate, IndexSearchMultiple, IndexPrintConfusionMatrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6939e3b2ce88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0membed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncodeLoad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncodeFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtext_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBPEfastApply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mindexing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndexCreate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexSearchMultiple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexPrintConfusionMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/LASER/source/embed.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLASER\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/source/lib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtext_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBPEfastApply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/LASER/source/lib/text_processing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfastBPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msubprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVNULL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastBPE'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iKRw4tSWb1jW"
      },
      "source": [
        "## These are the steps to replicate results of the LSTM file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c3ZY3F5ZbCwJ",
        "colab": {}
      },
      "source": [
        "MODEL_PATH = '/content/LASER/models/'\n",
        "sentence_encoder = SentenceEncoder(\n",
        "    str(MODEL_PATH + \"bilstm.93langs.2018-12-26.pt\"),\n",
        "    max_sentences=None,\n",
        "    max_tokens=10000,\n",
        "    cpu=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jTXpYPem32iM"
      },
      "source": [
        "## Load the entire dataset in this section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k30PCfcugynk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MzVaHR7VcQlH",
        "colab": {}
      },
      "source": [
        "# Replace filename at the end\n",
        "input_data = pd.read_csv('/gdrive/My Drive/data_23000_to_46000.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJ9OuN6fnEjE",
        "colab": {}
      },
      "source": [
        "input_data.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ImQg2ouIupGA",
        "colab": {}
      },
      "source": [
        "input_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gY_gevdXu8ZV"
      },
      "source": [
        "### We would use review.text as the input and use it to predict review.primaryCategories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cfzKSTw5vMvP",
        "colab": {}
      },
      "source": [
        "input_data.Product_Category.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HbUHtUzLl-T1",
        "colab": {}
      },
      "source": [
        "input_data = input_data.rename(columns={'Product_Category':'label'})\n",
        "input_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cm6KWbuh95tX",
        "colab": {}
      },
      "source": [
        "LASER = os.environ['LASER']\n",
        "FASTBPE = LASER + '/tools-external/fastBPE/fast'\n",
        "MOSES_BDIR = LASER + '/tools-external/moses-tokenizer/tokenizer/'\n",
        "MOSES_TOKENIZER = MOSES_BDIR + 'tokenizer.perl -q -no-escape -threads 20 -l '\n",
        "MOSES_LC = MOSES_BDIR + 'lowercase.perl'\n",
        "NORM_PUNC = MOSES_BDIR + 'normalize-punctuation.perl -l '\n",
        "DESCAPE = MOSES_BDIR + 'deescape-special-chars.perl'\n",
        "REM_NON_PRINT_CHAR = MOSES_BDIR + 'remove-non-printing-char.perl'\n",
        "MECAB = LASER + '/tools-external/mecab'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h9sXKsW1M9Xt",
        "colab": {}
      },
      "source": [
        "from subprocess import check_output\n",
        "def sample_token(string_val, lang='en'):\n",
        "    tok = check_output(\n",
        "                REM_NON_PRINT_CHAR\n",
        "                + '|' + NORM_PUNC + lang\n",
        "                + '|' + DESCAPE\n",
        "                + '|' + MOSES_TOKENIZER + lang\n",
        "                + ('| python3 -m jieba -d ' if lang == 'zh' else '')\n",
        "                + ('|' + MECAB + '/bin/mecab -O wakati -b 50000 ' if lang == 'ja' else ''),\n",
        "                input=string_val,\n",
        "                encoding='UTF-8',\n",
        "                shell=True)\n",
        "    return tok.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iT4TrHkYvT0Q"
      },
      "source": [
        "### Clean the data as that might cause problems later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "faPNpMFclPpq",
        "colab": {}
      },
      "source": [
        "index = input_data.reviewText.isnull()==True\n",
        "samp = index[index==True]\n",
        "input_data = input_data.drop(samp.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KID-p2ZpvZP9",
        "outputId": "35352057-8246-4393-b70e-c0a6a963a30c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_data.reviewText.isnull().sum() #Value should be always zero"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zmGwWzJZNkwZ",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Do the above mentioned operation on all the entries in the column. So,\n",
        "  \n",
        "\"\"\"\n",
        "input_data['tokenized_review'] = input_data.reviewText.apply(sample_token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyGL40Qeizzi",
        "colab_type": "code",
        "outputId": "57161a0a-9af7-42fd-b8b7-8492f60d6769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "input_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewText</th>\n",
              "      <th>label</th>\n",
              "      <th>tokenized_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is a really nice pocket knife, hurry and ...</td>\n",
              "      <td>Sports,Outdoors</td>\n",
              "      <td>This is a really nice pocket knife , hurry and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is one of my favorite Outkast CDs. But th...</td>\n",
              "      <td>Digital Music</td>\n",
              "      <td>This is one of my favorite Outkast CDs . But t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We bought this for our baking needs but have n...</td>\n",
              "      <td>Grocery and Gourmet</td>\n",
              "      <td>We bought this for our baking needs but have n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Alas, pianist Thelonious Monk was unable to ac...</td>\n",
              "      <td>CDs and Vinyl</td>\n",
              "      <td>Alas , pianist Thelonious Monk was unable to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I bought this for my Sigma DMC-15E, it allows ...</td>\n",
              "      <td>Musical Instruments</td>\n",
              "      <td>I bought this for my Sigma DMC-15E , it allows...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          reviewText  ...                                   tokenized_review\n",
              "0  This is a really nice pocket knife, hurry and ...  ...  This is a really nice pocket knife , hurry and...\n",
              "1  This is one of my favorite Outkast CDs. But th...  ...  This is one of my favorite Outkast CDs . But t...\n",
              "2  We bought this for our baking needs but have n...  ...  We bought this for our baking needs but have n...\n",
              "3  Alas, pianist Thelonious Monk was unable to ac...  ...  Alas , pianist Thelonious Monk was unable to a...\n",
              "4  I bought this for my Sigma DMC-15E, it allows ...  ...  I bought this for my Sigma DMC-15E , it allows...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sPBpVwpGROPc",
        "colab": {}
      },
      "source": [
        "bpe_codes = './LASER/models/93langs.fcodes'\n",
        "bpe_vocab = bpe_codes.replace('fcodes', 'fvocab')\n",
        "\n",
        "\n",
        "def apply_bpe(sentence):\n",
        "  sentence = sentence.replace('\\\\',\"\")\n",
        "  sentence = sentence.replace('\"','\\\\\"')\n",
        "  bpe = check_output(\n",
        "      'echo -n \"'+sentence +'\" | '+ FASTBPE + ' applybpe_stream '+  bpe_codes +' '+bpe_vocab,\n",
        "      encoding='UTF-8',\n",
        "      shell=True)\n",
        "  return bpe.strip()\n",
        "\n",
        "\n",
        "#input_data['tokenized_review_bpe'] = input_data.reviewText.apply(bpe_sentences)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sEgQx2HgZml4",
        "outputId": "fce28142-c790-47f7-d4a3-b3c66d146c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tok_sentence = '\"love the magnet easel ... \" slow motion me \"great for moving to different areas ... wish it had some sort of non skid pad on bottom though ...'\n",
        "apply_bpe(tok_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"@@ love the magn@@ et ea@@ sel ... \" slo@@ w motion me \"@@ great for mo@@ ving to different areas ... wish it had some sort of non sk@@ id pad on bot@@ tom though ...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq41BnItrj-7",
        "colab_type": "code",
        "outputId": "53880815-f53b-40f8-a590-68cfa4fb9413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "input_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewText</th>\n",
              "      <th>label</th>\n",
              "      <th>tokenized_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is a really nice pocket knife, hurry and ...</td>\n",
              "      <td>Sports,Outdoors</td>\n",
              "      <td>This is a really nice pocket knife , hurry and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is one of my favorite Outkast CDs. But th...</td>\n",
              "      <td>Digital Music</td>\n",
              "      <td>This is one of my favorite Outkast CDs . But t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We bought this for our baking needs but have n...</td>\n",
              "      <td>Grocery and Gourmet</td>\n",
              "      <td>We bought this for our baking needs but have n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Alas, pianist Thelonious Monk was unable to ac...</td>\n",
              "      <td>CDs and Vinyl</td>\n",
              "      <td>Alas , pianist Thelonious Monk was unable to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I bought this for my Sigma DMC-15E, it allows ...</td>\n",
              "      <td>Musical Instruments</td>\n",
              "      <td>I bought this for my Sigma DMC-15E , it allows...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          reviewText  ...                                   tokenized_review\n",
              "0  This is a really nice pocket knife, hurry and ...  ...  This is a really nice pocket knife , hurry and...\n",
              "1  This is one of my favorite Outkast CDs. But th...  ...  This is one of my favorite Outkast CDs . But t...\n",
              "2  We bought this for our baking needs but have n...  ...  We bought this for our baking needs but have n...\n",
              "3  Alas, pianist Thelonious Monk was unable to ac...  ...  Alas , pianist Thelonious Monk was unable to a...\n",
              "4  I bought this for my Sigma DMC-15E, it allows ...  ...  I bought this for my Sigma DMC-15E , it allows...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jB-DB0WB2_Rk",
        "colab": {}
      },
      "source": [
        "input_data.to_csv('/gdrive/My Drive/data_00000_to_23000_tokenized.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qHVv21bCcIXf",
        "colab": {}
      },
      "source": [
        "input_data['tokenized_review_bpe'] = input_data.tokenized_review.apply(apply_bpe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMwG_6gQvfvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data.to_csv('/gdrive/My Drive/data_00000_to_23000_tokenized.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zg4kEhpSJ8Re",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}